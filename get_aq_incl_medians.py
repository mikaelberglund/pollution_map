# -*- coding: utf-8 -*-
"""Get AQ.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bhu8E9VPcn29p_30TXq_DGJl18YA1s4f
"""

import requests as re
import pandas as pd
import ee
import numpy as np
import datetime
# from datetime import datetime as dt
import datetime as dt


#!earthengine authenticate
ee.Initialize()

### General parameters
sc = 50 #scale for ee image collection retrieval
start = '2020-06-12'
end = '2020-06-30'
rad = 10000
r = 0.01

if False:
    dftot = pd.read_pickle('dftot.pkl')
    dfs = pd.read_pickle('dfs.pkl')
    dfm = pd.read_pickle('dfm.pkl')

def add_date_id(df,date,i):
    df['date'] = date
    df['id'] = i
    val = df.columns.drop(['latitude', 'longitude', 'date', 'id'])[0]
    df['measurement'] = val
    df = df.rename(columns={val: 'pixel_value'})
    return df

def get_IC(dataset,temparea,start,end,band):
    landsat = ee.ImageCollection(dataset)
    landsat = landsat.filterBounds(temparea)
    landsat = landsat.filterDate(start, end)
    landsat = landsat.select([band])
    return landsat

def get_median(imagecol,ar):
    #im = imagecol.filterDate(start=d - dt.timedelta(days=day), opt_end=d)
    im = ee.Image(imagecol.median().unmask())
    im_test = im.addBands(ee.Image.pixelLonLat())
    im_test = im_test.reduceRegion(reducer=ee.Reducer.toList(), geometry=ar, maxPixels=1e13,
                                   scale=sc, tileScale=8)
    dft = pd.DataFrame(im_test.getInfo())
    return dft

def get_last(imagecol,s,e,ar,i,ee_dataset):
    found_last = False
    day = 1
    d = dt.datetime.strptime(e, '%Y-%m-%d')
    im_test = imagecol.filterDate(start=d - dt.timedelta(days=day), opt_end=d)
    if get_median(im_test, ar)['tropospheric_NO2_column_number_density'].sum()>0:
        print('For the whole testing period this location has data, possibly partly masked.')
    # test = get_median(im_test, ar)
    # print('Sum: ' + str(test['tropospheric_NO2_column_number_density'].sum()))
    # print('Mean: ' + str(test['tropospheric_NO2_column_number_density'].mean()))
    # print('Median: ' + str(test['tropospheric_NO2_column_number_density'].median()))
    # print('Max: ' + str(test['tropospheric_NO2_column_number_density'].max()))
    # print('No of NaN: ' + str(test['tropospheric_NO2_column_number_density'].isna().sum()))
    # print('Shape: ' + str(test['tropospheric_NO2_column_number_density'].shape))
        while ~found_last:
            im_test = imagecol.filterDate(start = d - dt.timedelta(days=day),opt_end = d)
            # im_temp = im_test
            im_test = ee.Image(im_test.first()).unmask()
            if verbose:
                print(d - dt.timedelta(days=day))
            if (im_test.getInfo() is not None):
                ds = dt.datetime.strftime(d - dt.timedelta(days=day), '%Y-%m-%d')
                testds = dt.datetime.strptime(ds,'%Y-%m-%d')>=dt.datetime.strptime(s,'%Y-%m-%d')
                if testds:
                    date = dt.datetime.utcfromtimestamp(ee.Date(im_test.get('system:time_start')).getInfo()['value'] / 1000.)\
                        .strftime('%Y-%m-%d %H:%M')
                    im_test = im_test.addBands(ee.Image.pixelLonLat())
                    im_test = im_test.reduceRegion(reducer=ee.Reducer.toList(), geometry=ar, maxPixels=1e13, scale=sc,tileScale=8) #TODO: Sätt maxPixels så att alla får samma storlek?
                    if (np.array(im_test.getInfo().get('tropospheric_NO2_column_number_density')).mean() > 0):
                        found_last = True
                        ### Fetch for all combinations of datasets and bands in ee_dataset
                        dftemp = pd.DataFrame()
                        for j in range(0, len(ee_dataset)):
                            ds = ee_dataset.loc[j, :].dataset
                            b = ee_dataset.loc[j, :].bands
                            if ee_dataset.loc[j, :].method == 'last':
                                IC = get_IC(ds,ar,s,e,b)
                                im_test = IC.filterDate(start=d - dt.timedelta(days=day), opt_end=d)
                                im_test = ee.Image(im_test.first()).unmask()
                                im_test = im_test.addBands(ee.Image.pixelLonLat())
                                im_test = im_test.reduceRegion(reducer=ee.Reducer.toList(), geometry=ar, maxPixels=1e13,
                                                               scale=100, tileScale=8)
                                if False:
                                    print('Value has shape: '+str(np.shape(im_test.getInfo().get(b)))+' and lat has: ' +
                                          str(np.shape(im_test.getInfo().get('latitude'))))
                                if np.shape(im_test.getInfo().get(b)) == np.shape(im_test.getInfo().get('latitude')):
                                    dft = pd.DataFrame(im_test.getInfo())
                                    dft = add_date_id(dft,date,i)
                                    # dft['date'] = date
                                    # dft['id'] = i
                                    # val = dft.columns.drop(['latitude', 'longitude', 'date', 'id'])[0]
                                    # dft['measurement'] = val
                                    # dft = dft.rename(columns={val: 'pixel_value'})
                                    dftemp = dftemp.append(dft,ignore_index=True)
                            elif ee_dataset.loc[j, :].method == 'median':
                                ds = ee_dataset.loc[j, :].dataset
                                b = ee_dataset.loc[j, :].bands
                                IC = get_IC(ds, ar, s, e, b)
                                dft = get_median(IC,ar)
                                dft = add_date_id(dft,date,i)
                                dftemp = dftemp.append(dft, ignore_index=True)
                        if verbose:
                            print('Found data on date: '+str(d - dt.timedelta(days=day)))
                            print('For location: ' + str(i) + '. Shape: ' + str(dftemp.shape))
                            #print('Indicies for dftemp are: '+str(dftemp.index))
                        # dftempp = dftemp
                        # dftemp = dftemp.pivot_table(values='pixel_value', index=['id','date','measurement', 'latitude'],
                        #                             columns='longitude').reset_index().fillna(method='pad').melt()
                        if i == "MX-28":
                            print('Hi')
                        return dftemp,date
                    else:
                        day += 1
                elif (im_test.getInfo() is None) & testds:
                    day += 1
                elif ~testds:
                    return pd.DataFrame(columns=['latitude','longitude','date','location']),0
    else:
        print('Found no data for the whole period for location.')
        return pd.DataFrame(columns=['latitude', 'longitude', 'date', 'location']), 0

def get_data(locations,country):
    ee_dataset = pd.DataFrame([
        ["COPERNICUS/S5P/NRTI/L3_NO2",'tropospheric_NO2_column_number_density','last'],
        ["COPERNICUS/S5P/NRTI/L3_NO2",'stratospheric_NO2_column_number_density','last'],
        ['COPERNICUS/S5P/NRTI/L3_AER_AI','absorbing_aerosol_index','last'],
        ['NASA/GLDAS/V021/NOAH/G025/T3H','Rainf_tavg','last'],
        ['NASA/GLDAS/V021/NOAH/G025/T3H','Wind_f_inst','last'],
        ['NASA/GLDAS/V021/NOAH/G025/T3H', 'Tair_f_inst','last'],
        ['NASA/GLDAS/V021/NOAH/G025/T3H', 'Qair_f_inst','last'],
        ['COPERNICUS/S5P/NRTI/L3_CO','CO_column_number_density','last'],
        ['COPERNICUS/S2', 'B2', 'median'], #Blue
        ['COPERNICUS/S2', 'B3', 'median'], #Green
        ['COPERNICUS/S2', 'B4', 'median'], #Red
        ['COPERNICUS/S2', 'B8', 'median'], #NIR
    ],columns=['dataset','bands','method'])
    today=dt.datetime.strftime(dt.date.today(),'%Y-%m-%d')
    start = '2020-06-12'
    end = '2020-06-30'
    r = 0.01
    dfm = pd.DataFrame()
    dfs = pd.DataFrame()
    for i in locations.id:
        location = re.get('https://api.openaq.org/v1/locations/' + str(i))
        l = location.json()['results']['location']
        if verbose:
            print('Fetching location: '+str(i) + ' called: '+str(l))
        templat = location.json()['results']['coordinates']['latitude']
        templon = location.json()['results']['coordinates']['longitude']
        temparea = ee.Geometry.Rectangle(templon + 2 * r, templat + r, templon - 2 * r, templat - r)
        landsat = get_IC(ee_dataset.loc[0,:][0],temparea,start,end,ee_dataset.loc[0,:][1])
        df,date = get_last(landsat,start, end, temparea,i,ee_dataset)
        df['location'] = l
        if date != 0:
            if verbose:
                print(df.pixel_value.describe())
            dfs = dfs.append(df) ### TODO: ALL VALUES SEEM TO BE SET TO ZERO.
        # if date!=0:
            rad =10000
            measurements = re.get(
                'https://api.openaq.org/v1/measurements?coordinates=' + str(templat) + ',' + str(templon) +'&date_from='+
                dt.datetime.strftime(dt.datetime.strptime(date, '%Y-%m-%d %H:%M') - dt.timedelta(hours=1), '%Y-%m-%d %H:%M')+
                '&date_to='+dt.datetime.strftime(dt.datetime.strptime(date, '%Y-%m-%d %H:%M') + dt.timedelta(hours=1), '%Y-%m-%d %H:%M')+
                '&radius='+str(rad)+'&parameter=no2&limit=1000') #TODO: Behöver det vara dagar och inte timmar diff för att hitta
            measurements = pd.DataFrame(measurements.json()['results'])
            dfm = dfm.append(measurements)
            if True:
                print('dfm: '+str(dfm.shape)+ ' & measurements: '+str(measurements.shape))
                # dfcoord = pd.DataFrame(measurements.json()['results']).coordinates.apply(pd.Series)
                # if ((dfcoord.latitude.unique() - templat) < (rad / 111000)).sum() / dfcoord.shape[0] == 0:
                #     print('Error: There is no measurements within ' + str(rad) + 'm.')

    if dfm.shape[0]>0:
        dfm.date = dfm.date.apply(pd.Series).utc
        dfm.date = pd.to_datetime(dfm.date)
        dfs.date = pd.to_datetime(dfs.date, format='%Y-%m-%d %H:%M', utc = True)
        dfs.date = dfs.date.dt.round(freq='H')
        # dftot = pd.merge(dfm,dfs,how='left',left_on=['location','date'],right_on=['location','date']) #TODO: Jag kanske måste göra en mer manuel merge för datum där jag väljer närmaste datum istället.
        dftott = pd.merge(dfm,dfs,how='left',left_on=['location'],right_on=['location'])
        #if dftott.count()[id] > 0:
        if dftott.count()['id'] > 0:
            print('Number of id in dftott is: ' + str(dftott.count()['id']))
            dftot = pd.DataFrame()
            for i in locations.id:
                df = dftott[dftott.id == i]
                df = df[(df.date_x - df.date_y)== (df.date_x - df.date_y).min()].drop(['date_y','coordinates'],axis='columns')
                dftot = dftot.append(df)
            dftot = dftot.dropna(axis='rows').drop_duplicates()
            #dftot = dftot.drop('coordinates',axis='columns').drop_duplicates()
            locations[['longitude','latitude']] = locations.coordinates.apply(pd.Series)

            if True:
                dfs.to_pickle('dfs '+str( country )+' '+str( today )+'.pkl')
                dfm.to_pickle('dfm '+str( country )+' '+str( today )+'.pkl')
            l = []
            for i in dftot.id.unique():
                for j in dftot.measurement.unique():
                    dft = dftot[dftot.measurement == j]
                    im = dft[dft.id == i][['latitude','longitude','pixel_value']]. \
                        drop_duplicates().pivot('latitude','longitude','pixel_value').values
                    l.append(np.shape(im))
            pd.DataFrame(l).max()
            x_train = np.empty(shape=(1, pd.DataFrame(l).max()[0], pd.DataFrame(l).max()[1], len(dftot.measurement.unique())))
            y_train = np.empty(shape=(1))

            temp = x_train
            for i in dftot.id.unique():
                k=0
                for j in df.measurement.unique():
                    print(k)
                    dft = dftot[dftot.measurement == j]
                    im = dft[dft.id == i][['latitude', 'longitude', 'pixel_value']] \
                        .drop_duplicates().pivot('latitude','longitude','pixel_value').values
                    if np.shape(im)[1]<pd.DataFrame(l).max()[1]:
                        im = np.pad(im, pad_width=((0,0),(0,1)), mode='edge')
                    if np.shape(im)[0]<pd.DataFrame(l ).max()[0]:
                        im = np.pad(im, pad_width=((0,1),(0,0)), mode='edge')
                    temp[0, :, :, k] = im
                    k=k+1
                x_train = np.append(x_train, temp, axis=0)
                y_train = np.append(y_train,[dftot[dftot.id == i].value.unique()[0]],axis=0)
            if verbose:
                print('x_train has shape: ' +str(np.shape(x_train)))
                print('y_train has shape: ' +str(np.shape(y_train)))
            np.save('x_train '+str( country )+' '+str( today )+'.npy', x_train)
            np.save('y_train '+str( country )+' '+str( today )+'.npy', y_train)
    elif dfm.shape[0] == 0:
        print('Error: Found zero measurements (dfm)')

    if verbose:
        print('Finished '+str( country ) +' for '+str( today ))


countries = re.get('https://api.openaq.org/v1/countries')
countries = pd.DataFrame(countries.json()['results'])
# countries.code.unique()
# countries = ['SE','NO','DK','DE','NL','UK']
# countries = ['DK','DE','NL','UK']
# countries = ['DK','DE','NL','UK']
verbose = True
# EXECUTE PER COUNTRY
for c in countries.sort_values(by='locations',axis='rows', ascending=False)[40:94].code:
    if verbose:
        print(' ')
        print('Fetching for: ' + str(countries[countries.code == c].name.values) + ' which contains ' +
              str(countries[countries.code == c].locations.values) + ' number of locations in total')
    locations = re.get('https://api.openaq.org/v1/locations?country[]='+str(c)+'&parameter=no2')
    locations = pd.DataFrame(locations.json()['results'])
    ### Checking if there's any measurements
    if locations.shape[0] > 0:
        lc = locations.coordinates.apply(pd.Series)
        measurements = re.get(
            'https://api.openaq.org/v1/measurements?country=' + str(c) + '&date_from=' +
            str(dt.datetime.strptime(start, '%Y-%m-%d')) + '&date_to=' + str(dt.datetime.strptime(end, '%Y-%m-%d')) +
            '&radius=' + str(rad) + '&parameter=no2&limit=1000')
        mc = pd.DataFrame(measurements.json()['results'])
        if mc.shape[0] > 0:
            mc = mc.coordinates.apply(pd.Series)
            if ((mc.latitude - lc.latitude) < r).sum() > 0:
                get_data(locations,c)
            else:
                print('Found no ground level measurements for ' + str(c))
    else:
        print('Found no relevant locations for '+str(c))

